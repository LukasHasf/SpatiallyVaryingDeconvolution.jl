var documenterSearchIndex = {"docs":
[{"location":"example_conf/#Example-configuration-file","page":"Example configuration file","title":"Example configuration file","text":"","category":"section"},{"location":"example_conf/","page":"Example configuration file","title":"Example configuration file","text":"This module expects all the configuration to be in a single YAML file, which should look like this:","category":"page"},{"location":"example_conf/","page":"Example configuration file","title":"Example configuration file","text":"data:\n    # Path to blurred data\n    x_path : ../training_data/Data/Simulated_Miniscope_2D_Training_data/\n    # Path to ground truth\n    y_path : ../training_data/Data/Ground_truth_downsampled/\n    # Data needs to be resized to be a power of two along each axis\n    resize_to : [64, 64]\n    # Should the data be centered?\n    center_psfs: true\n    # If center_psfs, which index corresponds to the central PSF? -1 means length \\div 2 + 1\n    reference_index: -1\n\nmodel:\n    # Depth of UNet\n    depth: 3\n    # Use attention gates when combining activations of encoding and decoding branch\n    attention: true\n    # Use dropout layers in convolution blocks\n    dropout: true\n    # Use separable convolution in convolution blocks\n    separable: true\n    # Concatenate all UNet activations and concolve them as a final step\n    final_attention: true\n\ntraining:\n    # Path to the PSF file\n    psfs_path: ../SpatiallyVaryingConvolution/comaPSF.mat\n    # Key under which the PSFs are stored\n    psfs_key: psfs\n    # How many training+testing samples to load from x_path and y_path\n    nrsamples: 1000\n    # How many epochs to train\n    epochs: 50\n    # The employed optimizer\n    optimizer: ADADelta\n    # How often should a plot of the evaluation of the model on the first test data be plotted? 0 for never\n    plot_interval: 1\n    # Where should that plot be saved?\n    plot_path: examples/training_progress/\n    # Should the losses be written to a log file?\n    log_losses: false\n    checkpoints:\n        # Should a previously trained model be loaded? [true, false, latest]\n        load_checkpoints: latest\n        # If load_checkpoints, what is the path to the checkpoint?\n        checkpoint_path: nothing\n        # Directory where new checkpoints will be saved\n        checkpoint_dir: examples/checkpoints/\n        # How often should a checkpoint be saved? 0 for never except for at the end of training\n        save_interval: 1","category":"page"},{"location":"example_conf/#The-options-in-detail","page":"Example configuration file","title":"The options in detail","text":"","category":"section"},{"location":"example_conf/","page":"Example configuration file","title":"Example configuration file","text":"Here's a list of what each field in the configuration field does:","category":"page"},{"location":"example_conf/","page":"Example configuration file","title":"Example configuration file","text":"x_path, y_path : The paths to the ground_truth and training dat directories. See Preparing the training data\nresize_to : The UNet implementation requires samples to be powers of 2 in size along each spatial dimension. Each sample is resized to the dimension specified by this.\ncenter_psfs, reference_index : If your PSFs are not already centered, set center_psfs to true and set the reference_index to the PSF closest to the center.\ndepth : The number of downsampling / upsampling steps in the UNet.\nattention : Boolean to indicate if the UNet should use attention gates.\ndropout : Boolean to indicate if the UNet should employ dopout-layers during training.\nseparable : Whether to use separable or regular convolutions in the UNet convolution layers.\nfinal_attention : Whether to add a convolution layer which processes all intermediate (upsampled) activations in the decoder path followed by an attention gate.\npsfs_path, psfs_key : Path to file containing the PSFs. mat files have dict-like structure, so you also need to provide the key with which one can access the PSFs array.\nnrsamples : The number of samples to load and train with. They will be divided into 70% training and 30% testing data.\nepochs : The number of epochs the model will be trained.\nlog_losses : Boolean to indicate if the train and test loss after each epoch should be saved into a file.\nplot_interval, plot_path : Plot the result of using the model on the first testing sample every plot_interval-th epoch and save the result in the directory plot_path. Set plot_interval to 0 to deactivate.\nload_checkpoints, checkpoint_path : You can continue training from a previously saved checkpoint. If you want to do so, set load_checkpoints to true and provide the path to the checkpoint you want to load. Alternatively, set load_checkpoints to latest to load the most recent checkpoint in checkpoint_dir. In that case, checkpoint_path is ignored.\ncheckpoint_dir, save_interval : During training, every save_interval-th epoch, a checkpoint will be saved into the directory checkpoint_dir. Set save_interval to 0 to disable this. At the end of training, a checkpoint will be saved regardless.","category":"page"},{"location":"function_reference/#Function-reference","page":"Function reference","title":"Function reference","text":"","category":"section"},{"location":"function_reference/","page":"Function reference","title":"Function reference","text":"start_training\nload_model","category":"page"},{"location":"function_reference/#SpatiallyVaryingDeconvolution.start_training","page":"Function reference","title":"SpatiallyVaryingDeconvolution.start_training","text":"start_training(; T=Float32, kwargs...)\n\nStart the training of a deconvolution network.\n\nAll numeric data will be of type T (default Float32).\n\nIf this function signature is called, all of the following keywords     need to be included in kwargs:\n\npsfs_path::String : Path to the file containing the psfs\npsfs_key::String : Key to access the PSFs in psfs_path\ncenter_psfs::Bool : Indicates if PSFs should be centered\npsf_ref_index<:Integer : Index of the reference PSF in the PSFs array\nnrsamples<:Integer : Number of samples to load for training and testing\ntruth_dir::String : Path to directory containing ground truth samples\nsim_dir::String : Path to directory containing simulated samples\nnewsize::Tuple{Int} : Size of resized sample data.\noptimizer<:Flux.Optimise.AbstractOptimiser : An instance of a Flux optimizer used for training the network\nload_checkpoints::Bool : Indicates whether a checkpoint should be loaded instead of starting from scratch\ndepth<:Integer : Depth of the UNet\nattention::Bool : Indicates whether to use attention gates in the UNet\ndropout::Bool : Indicates whether to use dropout layers in the conv-blocks of the UNet\nseparable::Bool : Indicates whether to use separable convolution filters in a conv-block\nfinal_attention::Bool : Indicates whether to use a final layer appending all activations in the expanding path and attention gating them\ncheckpoint_path::String : (If load_checkpoints) Path of checkpoint to load\nepochs<:Int : Number of epochs to train\ncheckpoint_dir::String : Directory in which to store checkpoints \nplot_interval<:Integer : Plot prediction of model on a test sample every plot_interval epochs\nplot_dir::String : Directory in which to save the generated plots\nsave_interval<:Integer : Save a checkpoint every save_interval epochs\nlogfile::Union{nothing, String} : Write to a logfile located at logfile ( or don't, if isnothing(logfile))\n\n\n\n\n\nstart_training(options_path; T=Float32)\n\nStart the training of a deconvolution network.\n\noptions_path is the path to the configuration YAML file. All numeric data will be of type T (default Float32).\n\n\n\n\n\n","category":"function"},{"location":"function_reference/#SpatiallyVaryingDeconvolution.load_model","page":"Function reference","title":"SpatiallyVaryingDeconvolution.load_model","text":"load_model(path; load_optimizer=true)\n\nLoad a MultiWienerNet from a checkpoint saved at path. Optionally load the optimizer  used for training with load_optimizer. Returns (model [, optimizer])\n\n\n\n\n\n","category":"function"},{"location":"#SpatiallyVaryingDeconvolution.jl","page":"SpatiallyVaryingDeconvolution.jl","title":"SpatiallyVaryingDeconvolution.jl","text":"","category":"section"},{"location":"","page":"SpatiallyVaryingDeconvolution.jl","title":"SpatiallyVaryingDeconvolution.jl","text":"This package provides model definitions and training facilities for the MultiWienerNet described in [1]. This model is capable of reverting the effect of a spatially varying convolution in 2D and 3D.","category":"page"},{"location":"#Installation","page":"SpatiallyVaryingDeconvolution.jl","title":"Installation","text":"","category":"section"},{"location":"","page":"SpatiallyVaryingDeconvolution.jl","title":"SpatiallyVaryingDeconvolution.jl","text":"julia> ] add https://github.com/LukasHasf/SpatiallyVaryingDeconvolution.jl","category":"page"},{"location":"#Quickstart","page":"SpatiallyVaryingDeconvolution.jl","title":"Quickstart","text":"","category":"section"},{"location":"","page":"SpatiallyVaryingDeconvolution.jl","title":"SpatiallyVaryingDeconvolution.jl","text":"Training the model is as simple as calling train_model on your configuration file:","category":"page"},{"location":"","page":"SpatiallyVaryingDeconvolution.jl","title":"SpatiallyVaryingDeconvolution.jl","text":"using SpatiallyVaryingDeconvolution\nstart_training(\"myOptions.yaml\")","category":"page"},{"location":"","page":"SpatiallyVaryingDeconvolution.jl","title":"SpatiallyVaryingDeconvolution.jl","text":"myOptions.yaml should use all the fields the example configuration file defines.","category":"page"},{"location":"#Preparing-the-training-data","page":"SpatiallyVaryingDeconvolution.jl","title":"Preparing the training data","text":"","category":"section"},{"location":"","page":"SpatiallyVaryingDeconvolution.jl","title":"SpatiallyVaryingDeconvolution.jl","text":"In order to train the model, you need to provide training data, ground truth data and the PSFs. Per sample of data, there should be a file in the training data directory and the ground truth data directory each. Supported file formats are png for 2D and mat or HDF5 for 3D . An example directory structure might look like this:","category":"page"},{"location":"","page":"SpatiallyVaryingDeconvolution.jl","title":"SpatiallyVaryingDeconvolution.jl","text":"├── ground_truth_data\n│   ├── 001.png\n│   ├── 002.png\n│   └── 003.png\n└── training_data\n    ├── 001.png\n    ├── 002.png\n    └── 003.png","category":"page"},{"location":"","page":"SpatiallyVaryingDeconvolution.jl","title":"SpatiallyVaryingDeconvolution.jl","text":"The PSFs should be provided in a single Matlab/HDF5 file as an 3D/4D array with the 2/3 first dimension being the spatial dimensions.","category":"page"},{"location":"","page":"SpatiallyVaryingDeconvolution.jl","title":"SpatiallyVaryingDeconvolution.jl","text":"The paths to the ground truth data directory, the training data directory and the PSFs should be set in your options.yaml in the fields x_path, y_path and psfs_path, respectively. Note that if you use relative paths, they will be relative to your current working directory and not the directory where the options.yaml file is located.","category":"page"},{"location":"#Usage-after-training","page":"SpatiallyVaryingDeconvolution.jl","title":"Usage after training","text":"","category":"section"},{"location":"","page":"SpatiallyVaryingDeconvolution.jl","title":"SpatiallyVaryingDeconvolution.jl","text":"After training, you will have a fully trained MultiWienerNet saved as a checkpoint. This checkpoint can be loaded and used like a normal function:","category":"page"},{"location":"","page":"SpatiallyVaryingDeconvolution.jl","title":"SpatiallyVaryingDeconvolution.jl","text":"using SpatiallyVaryingDeconvolution\nmodel = load_model(checkpoint_path; load_optimizer=false)\n# Apply model to new blurry data\ndeblurred = model(blurry)","category":"page"},{"location":"#Sources","page":"SpatiallyVaryingDeconvolution.jl","title":"Sources","text":"","category":"section"},{"location":"","page":"SpatiallyVaryingDeconvolution.jl","title":"SpatiallyVaryingDeconvolution.jl","text":"[1] : Yanny, K., Antipa, N., Liberti, W., Dehaeck, S., Monakhova, K., Liu, F. L., Shen, K., Ng, R., & Waller, L. (2020). Miniscope3D: optimized single-shot miniature 3D fluorescence microscopy. In Light: Science &amp; Applications (Vol. 9, Issue 1). Springer Science and Business Media LLC. https://doi.org/10.1038/s41377-020-00403-7 ","category":"page"}]
}
